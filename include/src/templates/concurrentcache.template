#ifndef _CACHEPP_CONCURRENTCACHE_TEMPLATE
#define _CACHEPP_CONCURRENTCACHE_TEMPLATE

#include "libs/exceptionpp/exception.h"

#include "src/concurrentcache.h"

template <typename D, typename T> cachepp::ConcurrentCache<D, T>::ConcurrentCache(cachepp::identifier size) {
	this->size = size;
	for(cachepp::identifier i = 0; i < this->size; ++i) {
		this->cache_l.push_back(std::shared_ptr<std::recursive_mutex> (new std::recursive_mutex()));
	}
}

template <typename D, typename T> void cachepp::ConcurrentCache<D, T>::acquire(const std::shared_ptr<T>& arg) {
	this->cache_l.at(this->index(arg))->lock();
	if(!arg->get_is_loaded()) {
		this->cache_l.at(this->index(arg))->unlock();
		this->allocate(arg);
	}
}

template <typename D, typename T> void cachepp::ConcurrentCache<D, T>::release(const std::shared_ptr<T>& arg) {
	this->cache_l.at(this->index(arg))->unlock();
}

template <typename D, typename T> void cachepp::ConcurrentCache<D, T>::clear() {
	// fundamentally we need to make this->cache's size atomic -- map.insert and map.erase therefore must be wrapped with a lock
	std::lock_guard<std::recursive_mutex> l (this->l);
	for(cachepp::identifier i = 0; i < this->size; ++i) {
		this->cache_l.at(i)->lock();
	}
	for(typename std::map<cachepp::identifier, std::shared_ptr<T>>::iterator it = this->cache.begin(); it != this->cache.end();) {
		this->cache.erase(it->first);
		it->second->unload();
		it++;
	}
	for(cachepp::identifier i = 0; i < this->size; ++i) {
		this->cache_l.at(i)->unlock();
	}
}

template <typename D, typename T> void cachepp::ConcurrentCache<D, T>::allocate(const std::shared_ptr<T>& arg) {
	// fundamentally we need to make this->cache's size atomic -- map.insert and map.erase therefore must be wrapped with a lock
	std::lock_guard<std::recursive_mutex> l (this->l);

	this->cache_l.at(this->index(arg))->lock();

	// competing call may have already allocated this line
	if(arg->get_is_loaded()) {
		return;
	}

	if(this->cache.size() >= this->size) {
		std::shared_ptr<T> target = this->select();
		this->cache.erase(target->get_identifier());
		target->unload();
	}
	arg->load();
	this->cache.insert(std::pair<cachepp::identifier, std::shared_ptr<T>> (arg->get_identifier(), arg));
}

template <typename D, typename T> std::shared_ptr<T> cachepp::ConcurrentCache<D, T>::select() {
	std::vector<cachepp::identifier> candidates;

	// we are guaranteed to have at least one candidate -- we are currently holding onto one lock
	for(typename std::map<cachepp::identifier, std::shared_ptr<T>>::iterator it = this->cache.begin(); it != this->cache.end(); ++it) {
		if(this->cache_l.at(this->index(it->second))->try_lock()) {
			candidates.push_back(it->first);
		}
	}

	cachepp::identifier heuristic = 0;
	cachepp::identifier target = 0;
	for(std::vector<cachepp::identifier>::iterator it = candidates.begin(); it != candidates.end(); ++it) {
		cachepp::identifier h = this->heuristic(this->cache.at(*it));
		if(h <= heuristic) {
			heuristic = h;
			target = *it;
		}
	}

	if(target == 0) {
		throw(exceptionpp::RuntimeError("cachepp::ConcurrentCache::select", "cannot find a target to evict"));
	}

	return(this->cache.at(target));
}

template <typename D, typename T> bool cachepp::ConcurrentCache<D, T>::in(const std::shared_ptr<T>& arg) {
	throw(exceptionpp::NotImplemented("cachepp::ConcurrentCache::in"));
}

#endif
